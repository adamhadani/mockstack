{% set ollama_response = ollama(request_json.messages, 'llama3.2') | json_escape %}
 {
   "id": "chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT",
   "object": "chat.completion",
   "created": 1741569952,
   "model": "gpt-4.1-2025-04-14",
   "choices": [
     {
       "index": 0,
       "message": {
         "role": "assistant",
         "content": "{{ ollama_response }}",
         "refusal": null,
         "annotations": []
       },
       "logprobs": null,
       "finish_reason": "stop"
     }
   ],
   "usage": {
     "prompt_tokens": {{ request_json.messages[-1].content | length }},
     "completion_tokens": {{ ollama_response | length }},
     "total_tokens": {{ request_json.messages[-1].content | length + ollama_response | length }},
     "prompt_tokens_details": {
       "cached_tokens": 0,
       "audio_tokens": 0
     },
     "completion_tokens_details": {
       "reasoning_tokens": 0,
       "audio_tokens": 0,
       "accepted_prediction_tokens": 0,
       "rejected_prediction_tokens": 0
     }
   },
   "service_tier": "default"
 }
